"""
SREAgents - Python Backend
ä½¿ç”¨ Claude Agent SDK å¤„ç†æ™ºèƒ½ä½“å¯¹è¯å’ŒæŠ€èƒ½æ‰§è¡Œ
"""
import asyncio
import os
import json
import logging
import zipfile
import tempfile
import shutil
from datetime import datetime
from pathlib import Path
from typing import Optional, List
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("sreagents")

# Load environment variables
load_dotenv()

# Import Claude Agent SDK
try:
    from claude_agent_sdk import query, ClaudeAgentOptions
    from claude_agent_sdk.types import StreamEvent
except ImportError:
    logger.warning("claude-agent-sdk not installed. Run: uv add claude-agent-sdk")
    query = None
    ClaudeAgentOptions = None
    StreamEvent = None

# Import storage manager
from storage.manager import storage

app = FastAPI(title="SREAgents API", version="1.0.0")

# CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    agentId: str
    message: str
    systemPrompt: Optional[str] = None


class ChatResponse(BaseModel):
    response: str
    toolsUsed: list[str] = []


@app.get("/")
async def root():
    return {"status": "ok", "message": "OpsAgent Platform API"}


@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "claude_sdk_available": query is not None,
        "env_configured": bool(os.getenv("ANTHROPIC_API_KEY")),
        "storage_type": storage.storage_type
    }


# ==================== Storage Config API ====================

class StorageConfig(BaseModel):
    type: str = "local"
    github_token: Optional[str] = None
    github_owner: Optional[str] = None
    github_repo: Optional[str] = None
    github_branch: str = "main"


@app.get("/api/storage/config")
async def get_storage_config():
    """è·å–å­˜å‚¨é…ç½®"""
    return storage.get_config()


@app.put("/api/storage/config")
async def update_storage_config(config: StorageConfig):
    """æ›´æ–°å­˜å‚¨é…ç½®"""
    success = await storage.configure(config.model_dump())
    if success:
        return {"success": True, "config": storage.get_config()}
    raise HTTPException(status_code=500, detail="Failed to configure storage")


# Legacy directories (for backward compatibility)
SKILLS_DIR = Path(__file__).parent / "skills"
SKILLS_DIR.mkdir(exist_ok=True)

AGENTS_DIR = Path(__file__).parent / "agents"
AGENTS_DIR.mkdir(exist_ok=True)

CHAT_HISTORY_DIR = Path(__file__).parent / "chat_history"
CHAT_HISTORY_DIR.mkdir(exist_ok=True)

PROJECTS_DIR = Path(__file__).parent / "projects"
PROJECTS_DIR.mkdir(exist_ok=True)


def parse_skill_file(file_path: Path) -> dict:
    """è§£ææŠ€èƒ½ Markdown æ–‡ä»¶ï¼Œæå– frontmatter å’Œå†…å®¹"""
    # å°è¯•å¤šç§ç¼–ç 
    content = None
    for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'latin-1']:
        try:
            content = file_path.read_text(encoding=encoding)
            break
        except UnicodeDecodeError:
            continue
    
    if content is None:
        # æœ€åå°è¯•äºŒè¿›åˆ¶è¯»å–å¹¶å¿½ç•¥é”™è¯¯
        content = file_path.read_bytes().decode('utf-8', errors='ignore')
    
    # Parse YAML frontmatter
    if content.startswith("---"):
        parts = content.split("---", 2)
        if len(parts) >= 3:
            import yaml
            frontmatter = yaml.safe_load(parts[1])
            instruction = parts[2].strip()
            return {
                "id": file_path.stem,
                "name": frontmatter.get("name", file_path.stem) if frontmatter else file_path.stem,
                "description": frontmatter.get("description", "") if frontmatter else "",
                "icon": frontmatter.get("icon", "ğŸ”§") if frontmatter else "ğŸ”§",
                "instruction": instruction,
                "config": frontmatter.get("config", {}) if frontmatter else {},
                "documents": []
            }
    
    # No frontmatter
    return {
        "id": file_path.stem,
        "name": file_path.stem,
        "description": "",
        "icon": "ğŸ”§",
        "instruction": content,
        "config": {},
        "documents": []
    }


def save_skill_file(skill: dict):
    """ä¿å­˜æŠ€èƒ½ä¸ºç›®å½•ç»“æ„ (skills/{id}/SKILL.md)"""
    import yaml
    
    skill_dir = SKILLS_DIR / skill['id']
    skill_dir.mkdir(parents=True, exist_ok=True)
    
    frontmatter = {
        "name": skill.get("name", ""),
        "description": skill.get("description", ""),
        "icon": skill.get("icon", "ğŸ”§"),
    }
    if skill.get("config"):
        frontmatter["config"] = skill["config"]
    
    content = f"""---
{yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False).strip()}
---

{skill.get("instruction", "")}
"""
    
    file_path = skill_dir / "SKILL.md"
    file_path.write_text(content, encoding="utf-8")
    return skill_dir


def get_skill_md_path(skill_id: str) -> Optional[Path]:
    """è·å– skill çš„ SKILL.md è·¯å¾„ï¼Œå…¼å®¹ç›®å½•å’Œå•æ–‡ä»¶ä¸¤ç§ç»“æ„"""
    # ä¼˜å…ˆæ£€æŸ¥ç›®å½•ç»“æ„
    skill_dir = SKILLS_DIR / skill_id
    if skill_dir.is_dir():
        for name in ['SKILL.md', 'skill.md', 'Skill.md']:
            md_path = skill_dir / name
            if md_path.exists():
                return md_path
    # å…¼å®¹æ—§çš„å•æ–‡ä»¶ç»“æ„
    old_path = SKILLS_DIR / f"{skill_id}.md"
    if old_path.exists():
        return old_path
    return None


@app.get("/api/skills")
async def list_skills():
    """è·å–æ‰€æœ‰æŠ€èƒ½åˆ—è¡¨"""
    skills = []
    seen_ids = set()
    
    # æ‰«æç›®å½•ç»“æ„
    for item in SKILLS_DIR.iterdir():
        if item.is_dir() and not item.name.startswith('.'):
            skill_md = None
            for name in ['SKILL.md', 'skill.md', 'Skill.md']:
                if (item / name).exists():
                    skill_md = item / name
                    break
            if skill_md:
                try:
                    skill = parse_skill_file(skill_md)
                    skill["id"] = item.name
                    skills.append(skill)
                    seen_ids.add(item.name)
                except Exception as e:
                    logger.error("Error parsing %s: %s", skill_md, e)
    
    # å…¼å®¹æ—§çš„å•æ–‡ä»¶ç»“æ„
    for file_path in SKILLS_DIR.glob("*.md"):
        if file_path.stem not in seen_ids:
            try:
                skill = parse_skill_file(file_path)
                skills.append(skill)
            except Exception as e:
                logger.error("Error parsing %s: %s", file_path, e)
    
    return {"skills": skills}


@app.get("/api/skills/{skill_id}")
async def get_skill(skill_id: str):
    """è·å–å•ä¸ªæŠ€èƒ½è¯¦æƒ…"""
    md_path = get_skill_md_path(skill_id)
    if not md_path:
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    skill = parse_skill_file(md_path)
    skill["id"] = skill_id
    return skill


class SkillCreate(BaseModel):
    id: Optional[str] = None
    name: str
    description: str = ""
    icon: str = "ğŸ”§"
    instruction: str = ""
    config: dict = {}


@app.post("/api/skills")
async def create_skill(skill: SkillCreate):
    """åˆ›å»ºæ–°æŠ€èƒ½"""
    skill_dict = skill.model_dump()
    if not skill_dict.get("id"):
        skill_dict["id"] = skill_dict["name"].lower().replace(" ", "-")
    
    skill_dir = SKILLS_DIR / skill_dict['id']
    if skill_dir.exists():
        raise HTTPException(status_code=400, detail=f"Skill '{skill_dict['id']}' already exists")
    
    save_skill_file(skill_dict)
    return {"success": True, "skill": skill_dict}


@app.put("/api/skills/{skill_id}")
async def update_skill(skill_id: str, skill: SkillCreate):
    """æ›´æ–°æŠ€èƒ½"""
    md_path = get_skill_md_path(skill_id)
    if not md_path:
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    
    skill_dict = skill.model_dump()
    skill_dict["id"] = skill_id
    save_skill_file(skill_dict)
    return {"success": True, "skill": skill_dict}


@app.delete("/api/skills/{skill_id}")
async def delete_skill(skill_id: str):
    """åˆ é™¤æŠ€èƒ½"""
    skill_dir = SKILLS_DIR / skill_id
    if skill_dir.is_dir():
        shutil.rmtree(skill_dir)
        return {"success": True}
    
    # å…¼å®¹æ—§çš„å•æ–‡ä»¶
    file_path = SKILLS_DIR / f"{skill_id}.md"
    if file_path.exists():
        file_path.unlink()
        return {"success": True}
    
    raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")


@app.get("/api/skills/{skill_id}/files")
async def list_skill_files(skill_id: str):
    """è·å–æŠ€èƒ½ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"""
    skill_dir = SKILLS_DIR / skill_id
    if not skill_dir.is_dir():
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    
    files = []
    for item in skill_dir.rglob("*"):
        if item.is_file():
            rel_path = str(item.relative_to(skill_dir))
            files.append({
                "name": item.name,
                "path": rel_path,
                "size": item.stat().st_size,
                "isSkillMd": item.name.upper() == "SKILL.MD"
            })
    return {"files": files}


@app.get("/api/skills/{skill_id}/files/{file_path:path}")
async def get_skill_file(skill_id: str, file_path: str):
    """è·å–æŠ€èƒ½ç›®å½•ä¸‹çš„å•ä¸ªæ–‡ä»¶å†…å®¹"""
    skill_dir = SKILLS_DIR / skill_id
    if not skill_dir.is_dir():
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    
    target_file = skill_dir / file_path
    if not target_file.exists() or not target_file.is_file():
        raise HTTPException(status_code=404, detail=f"File '{file_path}' not found")
    
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨ skill ç›®å½•å†…
    try:
        target_file.resolve().relative_to(skill_dir.resolve())
    except ValueError:
        raise HTTPException(status_code=403, detail="Access denied")
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    try:
        content = target_file.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        content = target_file.read_bytes().decode("utf-8", errors="ignore")
    
    return {"path": file_path, "content": content}


class FileContent(BaseModel):
    content: str


@app.put("/api/skills/{skill_id}/files/{file_path:path}")
async def update_skill_file(skill_id: str, file_path: str, body: FileContent):
    """æ›´æ–°æŠ€èƒ½ç›®å½•ä¸‹çš„å•ä¸ªæ–‡ä»¶"""
    skill_dir = SKILLS_DIR / skill_id
    if not skill_dir.is_dir():
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    
    target_file = skill_dir / file_path
    
    # å®‰å…¨æ£€æŸ¥
    try:
        target_file.resolve().relative_to(skill_dir.resolve())
    except ValueError:
        raise HTTPException(status_code=403, detail="Access denied")
    
    # åˆ›å»ºçˆ¶ç›®å½•
    target_file.parent.mkdir(parents=True, exist_ok=True)
    target_file.write_text(body.content, encoding="utf-8")
    
    return {"success": True}


@app.post("/api/skills/{skill_id}/files")
async def create_skill_file(skill_id: str, file_path: str, body: FileContent):
    """åœ¨æŠ€èƒ½ç›®å½•ä¸‹åˆ›å»ºæ–°æ–‡ä»¶"""
    skill_dir = SKILLS_DIR / skill_id
    if not skill_dir.is_dir():
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    
    target_file = skill_dir / file_path
    
    # å®‰å…¨æ£€æŸ¥
    try:
        target_file.resolve().relative_to(skill_dir.resolve())
    except ValueError:
        raise HTTPException(status_code=403, detail="Access denied")
    
    if target_file.exists():
        raise HTTPException(status_code=400, detail=f"File '{file_path}' already exists")
    
    target_file.parent.mkdir(parents=True, exist_ok=True)
    target_file.write_text(body.content, encoding="utf-8")
    
    return {"success": True, "path": file_path}


@app.delete("/api/skills/{skill_id}/files/{file_path:path}")
async def delete_skill_file(skill_id: str, file_path: str):
    """åˆ é™¤æŠ€èƒ½ç›®å½•ä¸‹çš„æ–‡ä»¶"""
    skill_dir = SKILLS_DIR / skill_id
    if not skill_dir.is_dir():
        raise HTTPException(status_code=404, detail=f"Skill '{skill_id}' not found")
    
    target_file = skill_dir / file_path
    
    # ä¸å…è®¸åˆ é™¤ SKILL.md
    if target_file.name.upper() == "SKILL.MD":
        raise HTTPException(status_code=400, detail="Cannot delete SKILL.md")
    
    # å®‰å…¨æ£€æŸ¥
    try:
        target_file.resolve().relative_to(skill_dir.resolve())
    except ValueError:
        raise HTTPException(status_code=403, detail="Access denied")
    
    if not target_file.exists():
        raise HTTPException(status_code=404, detail=f"File '{file_path}' not found")
    
    target_file.unlink()
    return {"success": True}


@app.post("/api/skills/upload")
async def upload_skill(
    type: str = Form(...),
    file: Optional[UploadFile] = File(None),
    files: Optional[List[UploadFile]] = File(None),
    folderName: Optional[str] = Form(None)
):
    """ä¸Šä¼ æŠ€èƒ½æ–‡ä»¶
    
    æ”¯æŒ:
    - å•ä¸ª .md æ–‡ä»¶
    - .zip æ–‡ä»¶ï¼ˆæ ¹ç›®å½•åŒ…å« SKILL.mdï¼‰
    - æ–‡ä»¶å¤¹ä¸Šä¼ ï¼ˆåŒ…å« SKILL.mdï¼‰
    """
    imported_skills = []
    
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        extracted_dir = tmp_path / "extracted"
        extracted_dir.mkdir()
        
        if type == "file" and file:
            ext = file.filename.split('.')[-1].lower()
            
            if ext == 'md':
                # ç›´æ¥å¤„ç†å•ä¸ª .md æ–‡ä»¶
                content = await file.read()
                md_path = extracted_dir / file.filename
                md_path.write_bytes(content)
                
            elif ext in ['zip', 'skill']:
                # å¤„ç†å‹ç¼©åŒ…
                content = await file.read()
                zip_path = tmp_path / file.filename
                zip_path.write_bytes(content)
                
                try:
                    with zipfile.ZipFile(zip_path, 'r') as zf:
                        zf.extractall(extracted_dir)
                except zipfile.BadZipFile:
                    raise HTTPException(status_code=400, detail="æ— æ•ˆçš„å‹ç¼©æ–‡ä»¶")
            else:
                raise HTTPException(status_code=400, detail="æ”¯æŒ .mdã€.zip æ–‡ä»¶")
                
        elif type == "folder" and files:
            # å¤„ç†æ–‡ä»¶å¤¹ä¸Šä¼ 
            for f in files:
                if not f.filename:
                    continue
                # ä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
                rel_path = f.filename.split('/', 1)[-1] if '/' in f.filename else f.filename
                file_path = extracted_dir / rel_path
                file_path.parent.mkdir(parents=True, exist_ok=True)
                content = await f.read()
                file_path.write_bytes(content)
        else:
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ä¸Šä¼ å‚æ•°")
        
        # æŸ¥æ‰¾ SKILL.mdï¼ˆä¼˜å…ˆï¼‰æˆ–å…¶ä»– .md æ–‡ä»¶
        skill_md = None
        for name in ['SKILL.md', 'skill.md', 'Skill.md']:
            found = list(extracted_dir.rglob(name))
            if found:
                skill_md = found[0]
                break
        
        if not skill_md:
            # å°è¯•æ‰¾ä»»æ„ .md æ–‡ä»¶
            md_files = [f for f in extracted_dir.rglob("*.md") 
                       if f.name.lower() not in ['readme.md', 'changelog.md', 'license.md']]
            if md_files:
                skill_md = md_files[0]
        
        if not skill_md:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ° SKILL.md æ–‡ä»¶")
        
        try:
            skill = parse_skill_file(skill_md)
            
            # ç¡®å®š skill id
            if folderName:
                # å»æ‰ .skill åç¼€
                skill_id = folderName.replace('.skill', '').lower().replace(" ", "-")
            elif skill_md.parent != extracted_dir:
                # ä½¿ç”¨åŒ…å« SKILL.md çš„ç›®å½•å
                skill_id = skill_md.parent.name.replace('.skill', '').lower().replace(" ", "-")
            else:
                # ä½¿ç”¨æ–‡ä»¶å
                skill_id = skill_md.stem.lower().replace(" ", "-")
            
            skill["id"] = skill_id
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œæ·»åŠ åç¼€é¿å…å†²çª
            base_id = skill_id
            target_dir = SKILLS_DIR / skill_id
            if target_dir.exists() or (SKILLS_DIR / f"{skill_id}.md").exists():
                i = 1
                while (SKILLS_DIR / f"{base_id}-{i}").exists():
                    i += 1
                skill["id"] = f"{base_id}-{i}"
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            target_dir = SKILLS_DIR / skill["id"]
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ‰€æœ‰æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
            source_dir = skill_md.parent
            for item in source_dir.iterdir():
                if item.is_file():
                    # é‡å‘½åä¸º SKILL.mdï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰
                    if item.name.lower() in ['skill.md']:
                        shutil.copy(item, target_dir / "SKILL.md")
                    else:
                        shutil.copy(item, target_dir / item.name)
                elif item.is_dir():
                    shutil.copytree(item, target_dir / item.name)
            
            imported_skills.append(skill)
            
        except Exception as e:
            logger.error("Error importing skill: %s", e)
            raise HTTPException(status_code=400, detail=f"å¯¼å…¥å¤±è´¥: {str(e)}")

    return {
        "success": True,
        "imported": len(imported_skills),
        "skills": imported_skills
    }


# ==================== Agents API ====================

def parse_agent_file(file_path: Path) -> dict:
    """è§£ææ™ºèƒ½ä½“ Markdown æ–‡ä»¶"""
    import yaml
    content = file_path.read_text(encoding="utf-8")
    
    if content.startswith("---"):
        parts = content.split("---", 2)
        if len(parts) >= 3:
            frontmatter = yaml.safe_load(parts[1])
            system_prompt = parts[2].strip()
            return {
                "id": file_path.stem,
                "name": frontmatter.get("name", file_path.stem),
                "description": frontmatter.get("description", ""),
                "avatar": frontmatter.get("avatar", "ğŸ¤–"),
                "gradient": frontmatter.get("gradient", "gradient-1"),
                "model": frontmatter.get("model", "claude-3"),
                "skills": frontmatter.get("skills", []),
                "projectId": frontmatter.get("projectId", ""),
                "createdAt": frontmatter.get("createdAt", ""),
                "systemPrompt": system_prompt
            }
    
    return {
        "id": file_path.stem,
        "name": file_path.stem,
        "description": "",
        "avatar": "ğŸ¤–",
        "gradient": "gradient-1",
        "model": "claude-3",
        "skills": [],
        "projectId": "",
        "createdAt": "",
        "systemPrompt": content
    }


def save_agent_file(agent: dict):
    """ä¿å­˜æ™ºèƒ½ä½“ä¸º Markdown æ–‡ä»¶"""
    import yaml
    
    frontmatter = {
        "name": agent.get("name", ""),
        "description": agent.get("description", ""),
        "avatar": agent.get("avatar", "ğŸ¤–"),
        "gradient": agent.get("gradient", "gradient-1"),
        "model": agent.get("model", "claude-3"),
        "skills": agent.get("skills", []),
        "projectId": agent.get("projectId", ""),
        "createdAt": agent.get("createdAt", ""),
    }
    
    content = f"""---
{yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False).strip()}
---

{agent.get("systemPrompt", "")}
"""
    
    file_path = AGENTS_DIR / f"{agent['id']}.md"
    file_path.write_text(content, encoding="utf-8")
    return file_path


@app.get("/api/agents")
async def list_agents():
    """è·å–æ‰€æœ‰æ™ºèƒ½ä½“åˆ—è¡¨"""
    agents = []
    for file_path in AGENTS_DIR.glob("*.md"):
        try:
            agent = parse_agent_file(file_path)
            agents.append(agent)
        except Exception as e:
            logger.error("Error parsing %s: %s", file_path, e)
    return {"agents": agents}


@app.get("/api/agents/{agent_id}")
async def get_agent(agent_id: str):
    """è·å–å•ä¸ªæ™ºèƒ½ä½“è¯¦æƒ…"""
    file_path = AGENTS_DIR / f"{agent_id}.md"
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Agent '{agent_id}' not found")
    return parse_agent_file(file_path)


class AgentCreate(BaseModel):
    id: Optional[str] = None
    name: str
    description: str = ""
    avatar: str = "ğŸ¤–"
    gradient: str = "gradient-1"
    model: str = "claude-3"
    skills: list[str] = []
    projectId: str = ""
    createdAt: str = ""
    systemPrompt: str = ""


@app.post("/api/agents")
async def create_agent(agent: AgentCreate):
    """åˆ›å»ºæ–°æ™ºèƒ½ä½“"""
    agent_dict = agent.model_dump()
    if not agent_dict.get("id"):
        agent_dict["id"] = f"agent-{int(asyncio.get_event_loop().time() * 1000)}"
    if not agent_dict.get("createdAt"):
        from datetime import datetime
        agent_dict["createdAt"] = datetime.now().strftime("%Y/%m/%d")
    
    file_path = AGENTS_DIR / f"{agent_dict['id']}.md"
    if file_path.exists():
        raise HTTPException(status_code=400, detail=f"Agent '{agent_dict['id']}' already exists")
    
    save_agent_file(agent_dict)
    return {"success": True, "agent": agent_dict}


@app.put("/api/agents/{agent_id}")
async def update_agent(agent_id: str, agent: AgentCreate):
    """æ›´æ–°æ™ºèƒ½ä½“"""
    file_path = AGENTS_DIR / f"{agent_id}.md"
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Agent '{agent_id}' not found")
    
    agent_dict = agent.model_dump()
    agent_dict["id"] = agent_id
    save_agent_file(agent_dict)
    return {"success": True, "agent": agent_dict}


@app.delete("/api/agents/{agent_id}")
async def delete_agent(agent_id: str):
    """åˆ é™¤æ™ºèƒ½ä½“"""
    file_path = AGENTS_DIR / f"{agent_id}.md"
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Agent '{agent_id}' not found")
    
    file_path.unlink()
    return {"success": True}


# ==================== Chat History API ====================

class ChatMessage(BaseModel):
    role: str
    content: str


class ChatHistoryUpdate(BaseModel):
    messages: list[ChatMessage]


def get_chat_history_path(agent_id: str) -> Path:
    """è·å–å¯¹è¯å†å²æ–‡ä»¶è·¯å¾„"""
    return CHAT_HISTORY_DIR / f"{agent_id}.json"


@app.get("/api/chat/history/{agent_id}")
async def get_chat_history(agent_id: str):
    """è·å–æŒ‡å®šæ™ºèƒ½ä½“çš„å¯¹è¯å†å²"""
    file_path = get_chat_history_path(agent_id)
    if not file_path.exists():
        return {"messages": []}
    
    try:
        data = json.loads(file_path.read_text(encoding="utf-8"))
        return {"messages": data.get("messages", [])}
    except Exception as e:
        logger.error("Error reading chat history: %s", e)
        return {"messages": []}


@app.put("/api/chat/history/{agent_id}")
async def save_chat_history(agent_id: str, history: ChatHistoryUpdate):
    """ä¿å­˜å¯¹è¯å†å²"""
    file_path = get_chat_history_path(agent_id)
    data = {"messages": [msg.model_dump() for msg in history.messages]}
    file_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    return {"success": True}


@app.delete("/api/chat/history/{agent_id}")
async def clear_chat_history(agent_id: str):
    """æ¸…ç©ºå¯¹è¯å†å²"""
    file_path = get_chat_history_path(agent_id)
    if file_path.exists():
        file_path.unlink()
    return {"success": True}


@app.post("/api/chat")
async def chat(request: ChatRequest):
    """å¤„ç†æ™ºèƒ½ä½“å¯¹è¯è¯·æ±‚ - SSE æµå¼è¾“å‡º"""

    if not query:
        raise HTTPException(
            status_code=500,
            detail="Claude Agent SDK not installed. Run: uv add claude-agent-sdk"
        )

    if not os.getenv("ANTHROPIC_API_KEY"):
        raise HTTPException(
            status_code=500,
            detail="ANTHROPIC_API_KEY not configured in .env"
        )

    # åŠ è½½ agent ä¿¡æ¯
    agent_file = AGENTS_DIR / f"{request.agentId}.md"
    agent_data = {}
    if agent_file.exists():
        agent_data = parse_agent_file(agent_file)

    # æ„å»º system promptï¼šagent è‡ªèº«æç¤ºè¯ + é¡¹ç›®æ‹“æ‰‘ä¸Šä¸‹æ–‡
    base_prompt = request.systemPrompt or agent_data.get("systemPrompt", "") or "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¿ç»´åŠ©æ‰‹ã€‚"
    prompt_parts = [base_prompt]

    # æ³¨å…¥é¡¹ç›®æ‹“æ‰‘ä¿¡æ¯ï¼Œè®© agent äº†è§£å®ƒè´Ÿè´£çš„å¾®æœåŠ¡æ¶æ„
    project_id = agent_data.get("projectId", "")
    if project_id:
        project_file = PROJECTS_DIR / f"{project_id}.json"
        if project_file.exists():
            try:
                project = json.loads(project_file.read_text(encoding="utf-8"))
                topo = project.get("topology", {})
                nodes = topo.get("nodes", [])
                edges = topo.get("edges", [])
                if nodes:
                    prompt_parts.append(f"\n## ä½ è´Ÿè´£çš„é¡¹ç›®: {project.get('name', project_id)}")
                    prompt_parts.append("### æœåŠ¡æ‹“æ‰‘")
                    node_map = {}
                    for n in nodes:
                        node_map[n["id"]] = n.get("name", n["id"])
                        prompt_parts.append(f"- [{n.get('type', 'service')}] {n.get('name', n['id'])}")
                    if edges:
                        prompt_parts.append("### è°ƒç”¨å…³ç³»")
                        for e in edges:
                            src = node_map.get(e["from"], e["from"])
                            dst = node_map.get(e["to"], e["to"])
                            prompt_parts.append(f"- {src} â†’ {dst} ({e.get('type', 'calls')})")
            except Exception as e:
                logger.error("Failed to load project topology: %s", e)

    system_prompt = "\n\n".join(prompt_parts)

    async def event_stream():
        # è·Ÿè¸ª Skill å·¥å…·è°ƒç”¨ IDï¼Œè·³è¿‡å…¶å†…éƒ¨ç»“æœï¼ˆSkill åªæ˜¯åŠ è½½æŠ€èƒ½å®šä¹‰ï¼‰
        skill_tool_ids = set()
        streamed_text = False  # æ˜¯å¦å·²é€šè¿‡ delta æµå¼è¾“å‡ºè¿‡æ–‡æœ¬

        try:
            async for message in query(
                prompt=request.message,
                options=ClaudeAgentOptions(
                    system_prompt=system_prompt,
                    cwd=str(Path(__file__).parent),
                    setting_sources=["project"],
                    allowed_tools=["Skill", "Read", "Bash", "Glob", "WebFetch"],
                    permission_mode="acceptEdits",
                    max_turns=10,
                    include_partial_messages=True
                )
            ):
                # é€ token æµå¼è¾“å‡ºï¼ˆStreamEventï¼‰
                if StreamEvent and isinstance(message, StreamEvent):
                    event = message.event
                    event_type = event.get("type", "")
                    if event_type == "content_block_delta":
                        delta = event.get("delta", {})
                        if delta.get("type") == "text_delta":
                            text = delta.get("text", "")
                            if text:
                                streamed_text = True
                                data = json.dumps({"type": "delta", "content": text}, ensure_ascii=False)
                                yield f"data: {data}\n\n"
                    elif event_type == "content_block_start":
                        cb = event.get("content_block", {})
                        if cb.get("type") == "tool_use":
                            tool_name = cb.get("name", "")
                            tool_id = cb.get("id", "")
                            if tool_name == "Skill":
                                skill_tool_ids.add(tool_id)
                            else:
                                data = json.dumps({"type": "tool_start", "name": tool_name}, ensure_ascii=False)
                                yield f"data: {data}\n\n"

                # å®Œæ•´æ¶ˆæ¯
                elif hasattr(message, 'content') and message.content:
                    # æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å·¥å…· block
                    has_tool_block = any(
                        hasattr(b, 'name') and hasattr(b, 'input')
                        for b in message.content
                    )
                    for block in message.content:
                        if hasattr(block, 'text'):
                            # å¦‚æœæœ‰å·¥å…· blockï¼Œæ–‡æœ¬å·²é€šè¿‡ delta è¾“å‡ºï¼Œè·³è¿‡
                            # å¦‚æœæ— å·¥å…· blockï¼ˆçº¯æ–‡æœ¬å›å¤ï¼‰ï¼Œä¸”æœªé€šè¿‡ delta è¾“å‡ºï¼Œåˆ™å‘é€
                            if has_tool_block or streamed_text:
                                continue
                            if block.text:
                                data = json.dumps({"type": "text", "content": block.text}, ensure_ascii=False)
                                yield f"data: {data}\n\n"
                        elif hasattr(block, 'name') and hasattr(block, 'input'):
                            # ToolUseBlock â€” è·³è¿‡ Skillï¼ˆå†…éƒ¨å·¥å…·ï¼‰ï¼Œåªæ˜¾ç¤º Bash ç­‰
                            if block.name == "Skill":
                                if hasattr(block, 'id'):
                                    skill_tool_ids.add(block.id)
                                continue
                            tool_info = f"\n\n**ğŸ”§ {block.name}**"
                            inp = block.input
                            if isinstance(inp, dict) and inp.get("command"):
                                tool_info += f"\n```bash\n{inp['command']}\n```"
                            data = json.dumps({"type": "text", "content": tool_info}, ensure_ascii=False)
                            yield f"data: {data}\n\n"
                        elif hasattr(block, 'tool_use_id') and hasattr(block, 'content'):
                            # ToolResultBlock â€” è·³è¿‡ Skill ç»“æœ
                            if block.tool_use_id in skill_tool_ids:
                                continue
                            result_content = block.content
                            if isinstance(result_content, str) and result_content.strip():
                                truncated = result_content[:2000]
                                if len(result_content) > 2000:
                                    truncated += "\n... (ç»“æœå·²æˆªæ–­)"
                                result_text = f"\n\nğŸ“‹ æ‰§è¡Œç»“æœ:\n```\n{truncated}\n```\n\n"
                                data = json.dumps({"type": "text", "content": result_text}, ensure_ascii=False)
                                yield f"data: {data}\n\n"

            yield "data: [DONE]\n\n"
        except Exception as e:
            logger.error("Chat stream error: %s", e)
            data = json.dumps({"type": "error", "content": str(e)}, ensure_ascii=False)
            yield f"data: {data}\n\n"

    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"}
    )


@app.post("/api/skills/execute")
async def execute_skill(skill_name: str, params: dict = {}):
    """ç›´æ¥æ‰§è¡ŒæŒ‡å®šæŠ€èƒ½"""
    
    # é¢„å®šä¹‰æŠ€èƒ½æ‰§è¡Œé€»è¾‘
    skill_handlers = {
        "prometheus": execute_prometheus_skill,
    }
    
    handler = skill_handlers.get(skill_name)
    if not handler:
        raise HTTPException(status_code=404, detail=f"Skill '{skill_name}' not found")
    
    try:
        result = await handler(params)
        return {"success": True, "result": result}
    except Exception as e:
        return {"success": False, "error": str(e)}


async def execute_prometheus_skill(params: dict) -> dict:
    """æ‰§è¡Œ Prometheus æŠ€èƒ½ - æŸ¥è¯¢ç›‘æ§æŒ‡æ ‡"""
    import aiohttp
    
    prometheus_url = os.getenv("PROMETHEUS_URL", "http://localhost:9090")
    query_str = params.get("query", "up")
    
    async with aiohttp.ClientSession() as session:
        async with session.get(
            f"{prometheus_url}/api/v1/query",
            params={"query": query_str}
        ) as resp:
            if resp.status == 200:
                return await resp.json()
            else:
                text = await resp.text()
                raise Exception(f"Prometheus query failed: {text}")


# ==================== Projects API ====================

def get_project_path(project_id: str) -> Path:
    """è·å–é¡¹ç›®é…ç½®æ–‡ä»¶è·¯å¾„"""
    return PROJECTS_DIR / f"{project_id}.json"


def load_project(project_id: str) -> dict:
    """åŠ è½½é¡¹ç›®é…ç½®"""
    file_path = get_project_path(project_id)
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Project '{project_id}' not found")
    return json.loads(file_path.read_text(encoding="utf-8"))


def save_project(project: dict):
    """ä¿å­˜é¡¹ç›®é…ç½®"""
    file_path = get_project_path(project["id"])
    file_path.write_text(json.dumps(project, ensure_ascii=False, indent=2), encoding="utf-8")


@app.get("/api/projects")
async def list_projects():
    """è·å–æ‰€æœ‰é¡¹ç›®åˆ—è¡¨"""
    projects = []
    for file_path in PROJECTS_DIR.glob("*.json"):
        try:
            project = json.loads(file_path.read_text(encoding="utf-8"))
            # ç»Ÿè®¡æ™ºèƒ½ä½“æ•°é‡
            project["agentCount"] = len(project.get("agents", []))
            projects.append(project)
        except Exception as e:
            logger.error("Error loading project %s: %s", file_path, e)
    return {"projects": projects}


@app.get("/api/projects/{project_id}")
async def get_project(project_id: str):
    """è·å–å•ä¸ªé¡¹ç›®è¯¦æƒ…"""
    return load_project(project_id)


class ProjectCreate(BaseModel):
    name: str
    description: str = ""


class ProjectUpdate(BaseModel):
    name: Optional[str] = None
    description: Optional[str] = None
    topology: Optional[dict] = None
    agents: Optional[list[str]] = None


@app.post("/api/projects")
async def create_project(project: ProjectCreate):
    """åˆ›å»ºæ–°é¡¹ç›®"""
    from datetime import datetime
    project_id = f"proj-{int(asyncio.get_event_loop().time() * 1000)}"
    
    project_data = {
        "id": project_id,
        "name": project.name,
        "description": project.description,
        "createdAt": datetime.now().isoformat(),
        "topology": {"nodes": [], "edges": []},
        "agents": []
    }
    
    save_project(project_data)
    return {"success": True, "project": project_data}


@app.put("/api/projects/{project_id}")
async def update_project(project_id: str, update: ProjectUpdate):
    """æ›´æ–°é¡¹ç›®"""
    project = load_project(project_id)
    
    if update.name is not None:
        project["name"] = update.name
    if update.description is not None:
        project["description"] = update.description
    if update.topology is not None:
        project["topology"] = update.topology
    if update.agents is not None:
        project["agents"] = update.agents
    
    save_project(project)
    return {"success": True, "project": project}


@app.delete("/api/projects/{project_id}")
async def delete_project(project_id: str):
    """åˆ é™¤é¡¹ç›®"""
    file_path = get_project_path(project_id)
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Project '{project_id}' not found")
    file_path.unlink()
    return {"success": True}


@app.get("/api/projects/{project_id}/topology")
async def get_project_topology(project_id: str):
    """è·å–é¡¹ç›®çš„æœåŠ¡æ‹“æ‰‘"""
    project = load_project(project_id)
    return {"topology": project.get("topology", {"nodes": [], "edges": []})}


@app.put("/api/projects/{project_id}/topology")
async def update_project_topology(project_id: str, topology: dict):
    """æ›´æ–°é¡¹ç›®çš„æœåŠ¡æ‹“æ‰‘"""
    project = load_project(project_id)
    project["topology"] = topology
    save_project(project)
    return {"success": True}


# ==================== Scheduled Tasks API ====================

# å®šæ—¶ä»»åŠ¡å­˜å‚¨ç›®å½•
SCHEDULED_TASKS_DIR = Path(__file__).parent / "scheduled_tasks"
SCHEDULED_TASKS_DIR.mkdir(exist_ok=True)


class ScheduledTaskCreate(BaseModel):
    """åˆ›å»ºå®šæ—¶ä»»åŠ¡çš„è¯·æ±‚æ¨¡å‹"""
    name: str
    description: str = ""
    agentId: str
    projectId: Optional[str] = None
    cronExpression: str
    prompt: str
    enabled: bool = True


class ScheduledTaskUpdate(BaseModel):
    """æ›´æ–°å®šæ—¶ä»»åŠ¡çš„è¯·æ±‚æ¨¡å‹"""
    name: Optional[str] = None
    description: Optional[str] = None
    cronExpression: Optional[str] = None
    prompt: Optional[str] = None
    enabled: Optional[bool] = None


def get_task_path(task_id: str) -> Path:
    """è·å–ä»»åŠ¡æ–‡ä»¶è·¯å¾„"""
    return SCHEDULED_TASKS_DIR / f"{task_id}.json"


def load_task(task_id: str) -> dict:
    """åŠ è½½ä»»åŠ¡é…ç½®"""
    file_path = get_task_path(task_id)
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Task '{task_id}' not found")
    return json.loads(file_path.read_text(encoding="utf-8"))


def save_task(task: dict):
    """ä¿å­˜ä»»åŠ¡é…ç½®"""
    file_path = get_task_path(task["id"])
    file_path.write_text(json.dumps(task, ensure_ascii=False, indent=2), encoding="utf-8")


def get_execution_path(task_id: str, execution_id: str) -> Path:
    """è·å–æ‰§è¡Œè®°å½•æ–‡ä»¶è·¯å¾„"""
    return SCHEDULED_TASKS_DIR / task_id / "executions" / f"{execution_id}.json"


def load_execution(task_id: str, execution_id: str) -> dict:
    """åŠ è½½æ‰§è¡Œè®°å½•"""
    file_path = get_execution_path(task_id, execution_id)
    if not file_path.exists():
        raise HTTPException(status_code=404, detail=f"Execution '{execution_id}' not found")
    return json.loads(file_path.read_text(encoding="utf-8"))


def list_executions(task_id: str, limit: int = 20, offset: int = 0) -> tuple[list[dict], int]:
    """
    åˆ—å‡ºä»»åŠ¡çš„æ‰§è¡Œå†å²

    Returns:
        (æ‰§è¡Œè®°å½•åˆ—è¡¨, æ€»æ•°)
    """
    executions_dir = SCHEDULED_TASKS_DIR / task_id / "executions"
    if not executions_dir.exists():
        return [], 0

    # è¯»å–æ‰€æœ‰æ‰§è¡Œè®°å½•
    executions = []
    for exec_file in executions_dir.glob("*.json"):
        try:
            execution = json.loads(exec_file.read_text(encoding="utf-8"))
            executions.append(execution)
        except Exception as e:
            logger.error(f"Failed to load execution {exec_file}: {e}")

    # æŒ‰å¼€å§‹æ—¶é—´å€’åºæ’åº
    executions.sort(key=lambda x: x.get("startTime", ""), reverse=True)

    total = len(executions)
    return executions[offset:offset + limit], total


@app.get("/api/scheduled-tasks")
async def list_scheduled_tasks(
    agentId: Optional[str] = None,
    projectId: Optional[str] = None,
    enabled: Optional[bool] = None
):
    """è·å–å®šæ—¶ä»»åŠ¡åˆ—è¡¨"""
    tasks = []

    for task_file in SCHEDULED_TASKS_DIR.glob("*.json"):
        try:
            task = json.loads(task_file.read_text(encoding="utf-8"))

            # è¿‡æ»¤æ¡ä»¶
            if agentId and task.get("agentId") != agentId:
                continue
            if projectId and task.get("projectId") != projectId:
                continue
            if enabled is not None and task.get("enabled") != enabled:
                continue

            tasks.append(task)
        except Exception as e:
            logger.error(f"Failed to load task {task_file}: {e}")

    # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åº
    tasks.sort(key=lambda x: x.get("createdAt", ""), reverse=True)

    return {"tasks": tasks}


@app.get("/api/scheduled-tasks/{task_id}")
async def get_scheduled_task(task_id: str):
    """è·å–å®šæ—¶ä»»åŠ¡è¯¦æƒ…"""
    return load_task(task_id)


@app.post("/api/scheduled-tasks")
async def create_scheduled_task(task: ScheduledTaskCreate):
    """åˆ›å»ºå®šæ—¶ä»»åŠ¡"""
    # éªŒè¯ Agent æ˜¯å¦å­˜åœ¨
    agent_file = AGENTS_DIR / f"{task.agentId}.md"
    if not agent_file.exists():
        raise HTTPException(status_code=400, detail=f"Agent '{task.agentId}' not found")

    # éªŒè¯ Cron è¡¨è¾¾å¼
    if not task_scheduler.validate_cron_expression(task.cronExpression):
        raise HTTPException(status_code=400, detail=f"Invalid cron expression: {task.cronExpression}")

    # åˆ›å»ºä»»åŠ¡
    task_id = f"task-{int(asyncio.get_event_loop().time() * 1000)}"
    now = datetime.now().isoformat()

    task_data = {
        "id": task_id,
        "name": task.name,
        "description": task.description,
        "agentId": task.agentId,
        "projectId": task.projectId,
        "cronExpression": task.cronExpression,
        "prompt": task.prompt,
        "enabled": task.enabled,
        "createdAt": now,
        "updatedAt": now,
        "lastExecutedAt": None,
        "nextExecutionAt": None
    }

    # ä¿å­˜ä»»åŠ¡
    save_task(task_data)

    # å¦‚æœå¯ç”¨ï¼Œæ·»åŠ åˆ°è°ƒåº¦å™¨
    if task.enabled:
        await task_scheduler.add_task(task_data)

        # æ›´æ–° nextExecutionAt
        next_run = task_scheduler.get_next_run_time(task_id)
        if next_run:
            task_data["nextExecutionAt"] = next_run.isoformat()
            save_task(task_data)

    logger.info(f"Created task {task_id}: {task.name}")
    return {"success": True, "task": task_data}


@app.put("/api/scheduled-tasks/{task_id}")
async def update_scheduled_task(task_id: str, update: ScheduledTaskUpdate):
    """æ›´æ–°å®šæ—¶ä»»åŠ¡"""
    task = load_task(task_id)

    # æ›´æ–°å­—æ®µ
    if update.name is not None:
        task["name"] = update.name
    if update.description is not None:
        task["description"] = update.description
    if update.cronExpression is not None:
        # éªŒè¯æ–°çš„ Cron è¡¨è¾¾å¼
        if not task_scheduler.validate_cron_expression(update.cronExpression):
            raise HTTPException(status_code=400, detail=f"Invalid cron expression: {update.cronExpression}")
        task["cronExpression"] = update.cronExpression
    if update.prompt is not None:
        task["prompt"] = update.prompt
    if update.enabled is not None:
        task["enabled"] = update.enabled

    task["updatedAt"] = datetime.now().isoformat()

    # ä¿å­˜ä»»åŠ¡
    save_task(task)

    # æ›´æ–°è°ƒåº¦å™¨
    await task_scheduler.update_task(task)

    # æ›´æ–° nextExecutionAt
    if task["enabled"]:
        next_run = task_scheduler.get_next_run_time(task_id)
        if next_run:
            task["nextExecutionAt"] = next_run.isoformat()
            save_task(task)
    else:
        task["nextExecutionAt"] = None
        save_task(task)

    logger.info(f"Updated task {task_id}")
    return {"success": True, "task": task}


@app.delete("/api/scheduled-tasks/{task_id}")
async def delete_scheduled_task(task_id: str):
    """åˆ é™¤å®šæ—¶ä»»åŠ¡"""
    task_file = get_task_path(task_id)
    if not task_file.exists():
        raise HTTPException(status_code=404, detail=f"Task '{task_id}' not found")

    # ä»è°ƒåº¦å™¨ç§»é™¤
    await task_scheduler.remove_task(task_id)

    # åˆ é™¤ä»»åŠ¡æ–‡ä»¶
    task_file.unlink()

    # åˆ é™¤æ‰§è¡Œå†å²ç›®å½•
    executions_dir = SCHEDULED_TASKS_DIR / task_id
    if executions_dir.exists():
        import shutil
        shutil.rmtree(executions_dir)

    logger.info(f"Deleted task {task_id}")
    return {"success": True}


@app.post("/api/scheduled-tasks/{task_id}/enable")
async def enable_scheduled_task(task_id: str):
    """å¯ç”¨å®šæ—¶ä»»åŠ¡"""
    task = load_task(task_id)

    if task["enabled"]:
        return {"success": True, "task": task}

    task["enabled"] = True
    task["updatedAt"] = datetime.now().isoformat()
    save_task(task)

    # æ·»åŠ åˆ°è°ƒåº¦å™¨
    await task_scheduler.add_task(task)

    # æ›´æ–° nextExecutionAt
    next_run = task_scheduler.get_next_run_time(task_id)
    if next_run:
        task["nextExecutionAt"] = next_run.isoformat()
        save_task(task)

    logger.info(f"Enabled task {task_id}")
    return {"success": True, "task": task}


@app.post("/api/scheduled-tasks/{task_id}/disable")
async def disable_scheduled_task(task_id: str):
    """ç¦ç”¨å®šæ—¶ä»»åŠ¡"""
    task = load_task(task_id)

    if not task["enabled"]:
        return {"success": True, "task": task}

    task["enabled"] = False
    task["updatedAt"] = datetime.now().isoformat()
    task["nextExecutionAt"] = None
    save_task(task)

    # ä»è°ƒåº¦å™¨ç§»é™¤
    await task_scheduler.remove_task(task_id)

    logger.info(f"Disabled task {task_id}")
    return {"success": True, "task": task}


@app.post("/api/scheduled-tasks/{task_id}/trigger")
async def trigger_scheduled_task(task_id: str):
    """æ‰‹åŠ¨è§¦å‘ä»»åŠ¡æ‰§è¡Œ"""
    task = load_task(task_id)

    # å¼‚æ­¥æ‰§è¡Œä»»åŠ¡ï¼ˆä¸é˜»å¡ API å“åº”ï¼‰
    execution = await task_scheduler.execute_task(task_id)

    logger.info(f"Manually triggered task {task_id}, execution {execution['id']}")
    return {"success": True, "execution": execution}


@app.get("/api/scheduled-tasks/{task_id}/executions")
async def get_task_executions(task_id: str, limit: int = 20, offset: int = 0):
    """è·å–ä»»åŠ¡çš„æ‰§è¡Œå†å²"""
    # éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜åœ¨
    load_task(task_id)

    executions, total = list_executions(task_id, limit, offset)
    return {"executions": executions, "total": total}


@app.get("/api/scheduled-tasks/{task_id}/executions/{execution_id}")
async def get_task_execution(task_id: str, execution_id: str):
    """è·å–å•æ¬¡æ‰§è¡Œè¯¦æƒ…"""
    return load_execution(task_id, execution_id)


# ==================== Application Lifecycle ====================

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
task_scheduler = None


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–è°ƒåº¦å™¨"""
    global task_scheduler
    from scheduler import TaskScheduler

    # åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
    task_scheduler = TaskScheduler(
        tasks_dir=SCHEDULED_TASKS_DIR,
        agent_query_func=execute_agent_query
    )

    # å¯åŠ¨è°ƒåº¦å™¨
    await task_scheduler.start()

    logger.info("Application started successfully")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶åœæ­¢è°ƒåº¦å™¨"""
    global task_scheduler
    if task_scheduler:
        await task_scheduler.stop()

    logger.info("Application shutdown successfully")


async def execute_agent_query(agent_id: str, prompt: str):
    """
    æ‰§è¡Œ Agent æŸ¥è¯¢ï¼ˆä¾›è°ƒåº¦å™¨è°ƒç”¨ï¼‰

    Args:
        agent_id: Agent ID
        prompt: æç¤ºè¯

    Yields:
        Claude SDK è¿”å›çš„æ¶ˆæ¯æµ
    """
    if not query:
        raise Exception("Claude Agent SDK not installed")

    if not os.getenv("ANTHROPIC_API_KEY"):
        raise Exception("ANTHROPIC_API_KEY not configured")

    # åŠ è½½ agent ä¿¡æ¯
    agent_file = AGENTS_DIR / f"{agent_id}.md"
    if not agent_file.exists():
        raise Exception(f"Agent '{agent_id}' not found")

    agent_data = parse_agent_file(agent_file)

    # æ„å»º system prompt
    base_prompt = agent_data.get("systemPrompt", "") or "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¿ç»´åŠ©æ‰‹ã€‚"
    prompt_parts = [base_prompt]

    # æ³¨å…¥é¡¹ç›®æ‹“æ‰‘ä¿¡æ¯
    project_id = agent_data.get("projectId", "")
    if project_id:
        project_file = PROJECTS_DIR / f"{project_id}.json"
        if project_file.exists():
            try:
                project = json.loads(project_file.read_text(encoding="utf-8"))
                topo = project.get("topology", {})
                nodes = topo.get("nodes", [])
                edges = topo.get("edges", [])
                if nodes:
                    prompt_parts.append(f"\n## ä½ è´Ÿè´£çš„é¡¹ç›®: {project.get('name', project_id)}")
                    prompt_parts.append("### æœåŠ¡æ‹“æ‰‘")
                    node_map = {}
                    for n in nodes:
                        node_map[n["id"]] = n.get("name", n["id"])
                        prompt_parts.append(f"- [{n.get('type', 'service')}] {n.get('name', n['id'])}")
                    if edges:
                        prompt_parts.append("### è°ƒç”¨å…³ç³»")
                        for e in edges:
                            src = node_map.get(e["from"], e["from"])
                            dst = node_map.get(e["to"], e["to"])
                            prompt_parts.append(f"- {src} â†’ {dst} ({e.get('type', 'calls')})")
            except Exception as e:
                logger.error("Failed to load project topology: %s", e)

    system_prompt = "\n\n".join(prompt_parts)

    # è°ƒç”¨ Claude SDK
    async for message in query(
        prompt=prompt,
        options=ClaudeAgentOptions(
            system_prompt=system_prompt,
            cwd=str(Path(__file__).parent),
            setting_sources=["project"],
            allowed_tools=["Skill", "Read", "Bash", "Glob", "WebFetch"],
            permission_mode="acceptEdits",
            max_turns=10,
            include_partial_messages=True
        )
    ):
        yield message


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
